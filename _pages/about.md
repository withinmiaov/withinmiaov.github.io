---
permalink: /
title: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

This is ---

Publications
======

<div style="font-size: 14px;" markdown="1">


**[MICRO '25] Optimizing All-to-All Collective Communication with Fault Tolerance on Torus Networks**  \
Le Qin, Junwei Cui, **Weilin Cai**, Meng Niu, Yan Yang, Jiayi Huang  \
IEEE/ACM International Symposium on Microarchitecture, October 2025.

**[ICML '25] Shortcut-connected Expert Parallelism for Accelerating Mixture of Experts**  \
**Weilin Cai**, Juyong Jiang, Le Qin, Junwei Cui, Sunhung Kim, Jiayi Huang  \
International Conference on Machine Learning, July 2025.

**[ISCA '25] Chimera: Communication Fusion for Hybrid Parallelism in Large Language Models** <br>
Le Qin, Junwei Cui, **Weilin Cai**, Jiayi Huang <br>
ACM/IEEE International Symposium on Computer Architecture, June 2025. <br>
<span style="color: #B22222">Distinguished Artifact Award</span>

**[ASPLOS '25] MoC-System: Efficient Fault Tolerance for Sparse Mixture-of-Experts Model Training**\
**Weilin Cai**, Le Qin, Jiayi Huang\
ACM International Conference on Architectural Support for Programming Languages and Operating Systems, March—April 2025.

**[TKDE '25] A Survey on Mixture of Experts in Large Language Models**\
**Weilin Cai***, Juyong Jiang*, Fan Wang*, Jing Tang, Sunghun Kim, Jiayi Huang (\*: Equal contribution)\
IEEE Tranactions on Knowledge and Data Engineering, 37(7):3896—3915, March 2025.


</div>

